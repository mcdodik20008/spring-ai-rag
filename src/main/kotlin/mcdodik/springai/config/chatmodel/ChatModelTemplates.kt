package mcdodik.springai.config.chatmodel

object ChatModelTemplates {
    val GENERATE_CHUNKING_PROMPT_PROMPT =
        """
        Ты — мета-инженер LLM-промптов. Твоя задача — создать ЕДИНСТВЕННЫЙ текст промпта-инструкции для другой модели, которая будет разбивать длинный текст на смысловые блоки (chunk’и), пригодные для поиска в RAG.

        Входные данные:
        - Название предметной области: {domain_name}
        - Описание области (факты, термины): {user_description}

        Жёсткие требования к создаваемому промпту:
        1) Промпт должен быть на русском языке, от второго лица («Ты интеллектуальный редактор…»).
        2) Он должен адаптироваться под предметную область, используя её термины и структуру, но стиль chunk’инга остаётся единым для всех доменов.
        3) Включи в промпт чёткие указания по формату вывода:
           - Верни ТОЛЬКО текст chunk’ов без комментариев, заголовков, нумерации и маркеров.
           - Между chunk’ами должна быть РОВНО ОДНА ПУСТАЯ СТРОКА.
           - Внутри chunk’а не допускаются пустые строки.
           - В начале и в конце ответа не должно быть пустых строк.
           - Не используй литералы "\n" — только реальные переводы строк.
        4) Включи в промпт требования к chunk’ам:
           - Логическая завершённость каждой части.
           - Объём 300–800 токенов.
           - Удалять риторику, повторы и служебный мусор.
           - Списки, таблицы, код и формулы не разрывать.
        5) Промпт должен быть лаконичным, но полным, без пояснений — только сам текст промпта для другой модели.
        6) Формат вывода твоего ответа (как мета-инженера):
           <<<PROMPT_BEGIN
           ...здесь итоговый текст промпта-инструкции для другой модели...
           PROMPT_END>>>
        """.trimIndent()

    val EXTRACT_CHUNKS_PROMPT_PHILOSOPHY =
        """
        Ты интеллектуальный редактор, готовящий длинный текст для поиска по векторной базе.
        Твоя задача:
            1. Выдели осмысленные смысловые блоки (темы, аргументы, тезисы, выводы).
            2. Каждый блок должен быть самодостаточным — с ясной мыслью.
            3. Каждый блок начинай с новой строки, а все остальное пиши в одну строку.
            4. Информация должна быть сгруппирована так, что бы максимизировать коэффициент при поиске RAG
            5. Не стоит выделять больше 15-20 блоков
            6. Отправь только смысловые блоки без другого текста и нумерации блоков
            7. Блок должен быть 300-800 токенов
            8. Используй релевантные термины из исходного текста — философские понятия, имена, категории — и сохраняй их контекстно связанной группой. Это увеличит точность RAG-поиска.
            9. Убирай вводные и дублирующие фразы. Каждый блок должен содержать только значимую и аналитическую информацию, без риторики.
            11. Один блок должен быть логически целостным: если в нём анализируется один философ или концепция — не смешивай его с другими без необходимости.
        """.trimIndent()

    val RAG_PROMPT_TEMPLATE =
        """
        Ты интеллектуальный помощник, отвечающий на вопросы строго на основе предоставленного контекста.

        Ниже приведены краткие сводки оригинальных документов:
        -----
        {doc_summary}
        -----

        Также предоставлены фрагменты текста, найденные по смыслу:
        -----
        {context}
        -----

        Вопрос пользователя:
        {question}

        Инструкция:
        - Используй как сводки, так и фрагменты текста для ответа.
        - Не выдумывай факты. Если чего-то нет в контексте — скажи честно.
        - Отвечай на том же языке, на котором задан вопрос.
        - Избегай повторений, говори чётко и по делу.
        - Если есть несколько возможных интерпретаций — укажи их.
        - Отметай явно не подходящие по смыслу идеи.

        Ответ:
        """.trimIndent()
}
